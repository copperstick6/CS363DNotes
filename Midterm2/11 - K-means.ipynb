{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-means algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Choose K random data points from the training data to be initial centroids\n",
    "2. Each data point is assigned to be the closest centroid to form clusters\n",
    "3. Update the centroid of each cluster based on the mean of the points assigned to each cluster\n",
    "4. Reassign points to their closest centroid\n",
    "5. Repeat until no point changes cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clustering usually specified by an objective function and a proximity measure. With a proximity measure, the objective is to minimize SSE or scatter. These differ depending on the data and task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling empty clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If no points are assigned to the centroid, choose a new centroid. Three ways\n",
    "1. Randomly\n",
    "2. Point farthest away from any current centroid\n",
    "3. Choose a replacement from cluster with SSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-means ++"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose a random centroid, repeat until there are K centroids, compute distances from every point to nearest centroid, use squared distance as a probability distribution for choosing next centroid (farther more likely to be selected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bisecting K-means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To obtain K clusters, split the set of all data points into two clusters using K-means with K=2, keep splitting until you have K clusters, less susceptible to initialization problems and converges on better clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Characteristics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple and can be used for a wide variety of data points, efficient and have variations that are more efficient    \n",
    "Outliers can alter results, but this can be done before clustering.   \n",
    "Curse of Dimensionality - distance and similarity between points lose meaning as dimensionality increases.   \n",
    "Difficulties with non-globular data, clusters of different sizes and densities"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
