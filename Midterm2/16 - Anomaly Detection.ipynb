{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anomalies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data from different classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supervised vs Unsupervised"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supervised - requires a labeled training set with both normal and anomalous objects.    \n",
    "Unsupervised - detect which objects are anomalous based on data alone    \n",
    "Semi-supervised - Sometimes training data contains labeled normal data but has no anomalous objects, anything not adhering to modeled data is anomalous"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistical Approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model-based - create a model for the data, evaluate objects based on their probability under the model    \n",
    "Probabilitic Definition of an Outlier - an outlier is an object that has a low probability with respect to a probability distribution model of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mixture Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assumes the data is a mixture of two distributions - one for normal data points, one for outliers, goal is to find parameters of both distributions that maximize likelihood of data.    \n",
    "Define a distribution for all the data, then iteratively move data points from the normal set to the outlier set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Characteristics of Statistical Approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When there is sufficient knowledge of the data and type of distribution that should be applied, these tests have a firm statistical foundations and are very accurate and effective.    \n",
    "There are a lot of outlier tests for single attributes, less for multivariate, don't work for high dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proximity based approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An object is an outlier if it is distant from most other points, top n data points whose distance to the kth nearest neighbors is greatest or the top n points whose average distance to the k nearest neighbors is greatest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Density-based approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outliers are objects in regions of low density.   \n",
    "Defining density - count of points with a radius, inverse of average distance to k nearest neighbors   \n",
    "Struggles when data contains regions of differing densities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relative Density"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Relative density is the ratio of the density of point x to the average density of its k nearest neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Characteristics of Proximity and Density Based Approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More easily applied than statistical based approaches    \n",
    "Both proximity and density give a measure of the degree to which an object is an outlier.   \n",
    "Relative density can work even if there are regions of differing densities    \n",
    "Works in multi-dimensions but does suffer from curse of dimensionality.   \n",
    "O(m^2) time complexity.   \n",
    "Sensitive to parameter values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering based techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clustering finds groups of strongly related objects.   \n",
    "Anomalies are objects not strongly related to other objects.   \n",
    "Cluster data, then assess degree to which object belongs to any cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outliers impacting clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Approach 1: Cluster data, identify and remove outliers, cluster data without outliers.   \n",
    "Approach 2: have a group of objects that don't fit in any cluster, at each step in k-means objects that don't fit will are moved to outlier set, each outlier is then rechecked to see if they belong to new cluster, this set is the set of all outliers after clustering ends"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Isolation Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use trees to isolate each data point, randomly select feature, randomly select a value to split that feature, continue splitting until all data is isolate, keep track of splits    \n",
    "Keep a forest of these isolation trees, use number of splits required to isolate point as anomaly score, the smaller, the more likely it is an anomaly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Characteristics of Isolation Forests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No need to define any hyperpamaters, cheap computational cost, not susceptible to curse of dimensionality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One class SVMs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Used for novelty detection - data does not contain outliers but want to detect anomalies in new data   \n",
    "Use SVM to find hyperplane that separates data from origin, which side is this new data point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Characteristics of One-class SVMs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Used when no anomalous examples, can predict if new data points are unlike normal examples, requires a defined parameter, not susceptible to curse of dimensionality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approaches to anomaly detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model based techniques - build a model of the data, anomalies are points that do not fit model well.    \n",
    "Proximity based techniques - anomalous objects are those that are distant from most other objects.   \n",
    "Density based techniques - anomalous objects are in regions of low density.    \n",
    "Isolation based techniques - anomalous objects can be easily isolated"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
